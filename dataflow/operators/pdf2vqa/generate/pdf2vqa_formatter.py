import os
import json
import re
import shutil
from pathlib import Path
from typing import Literal
from dataflow.core import OperatorABC
from dataflow.utils.registry import OPERATOR_REGISTRY
from dataflow.utils.storage import DataFlowStorage
from dataflow import get_logger
from dataflow.utils.pdf2vqa.format_utils import merge_qa_pair, jsonl_to_md

@OPERATOR_REGISTRY.register()
class MinerU2LLMInputOperator(OperatorABC):
    def __init__(self):
        pass
    
    @staticmethod
    def get_desc(lang: str = "zh") -> str:
        if lang == 'zh':
            return (
                "MinerU格式转换为LLM输入格式算子。"
                "将MinerU生成的内容列表JSON文件转换为适合LLM处理的格式，"
                "包括展平列表项并重新编号。"
            )
        else:
            return (
                "Convert MinerU format to LLM input format operator."
                "Transforms the content list JSON file generated by MinerU into a format suitable for LLM processing,"
                "including flattening list items and re-indexing."
            )

    def _convert_json(self, input_file, output_file):
        with open(input_file, 'r') as infile:
            data = list(json.load(infile))
        
        new_data = []
        id = 0
        for item in data:
            item['id'] = id
            item.pop('bbox', None)
            item.pop('page_idx', None)
            if item.get('type','') == 'list':
                if item['sub_type'] == 'text':
                    for idx, list_item in enumerate(item.get('list_items', [])):
                        new_item = {
                            'type': 'text',
                            'text': list_item,
                            'id': id + idx,
                        }
                        new_data.append(new_item)
                    id += len(item.get('list_items', []))
            else:
                new_data.append(item)
                id += 1
        
        with open(output_file, 'w') as outfile:
            json.dump(new_data, outfile, ensure_ascii=False)
    
    def run(self, storage: DataFlowStorage,
            input_markdown_path_key,
            output_converted_layout_key,
            ):
        dataframe = storage.read("dataframe")
    
        for index, row in dataframe.iterrows():
            input_json_path = row[input_markdown_path_key].replace('.md', '_content_list.json')
            converted_path = input_json_path.replace('.json', '_converted.json')
            self._convert_json(input_json_path, converted_path)
            dataframe.at[index, output_converted_layout_key] = converted_path
            
            with open(converted_path, 'r') as infile:
                data = json.load(infile)
                assert isinstance(data, list), f"Expected list, got {type(data)} for {input_json_path}"
                
        storage.write(dataframe)
        
@OPERATOR_REGISTRY.register()
class LLMOutputParser(OperatorABC):
    def __init__(self, 
                 mode: Literal['question', 'answer'],
                 output_dir,
                 intermediate_dir: str = "intermediate",
                 ):
        self.logger = get_logger()
        self.mode = mode
        self.output_dir = output_dir
        self.intermediate_dir = intermediate_dir
        
    @staticmethod
    def get_desc(lang: str = "zh") -> str:
        if lang == 'zh':
            return (
                "LLM输出解析算子。"
                "将LLM生成的包含题目和答案ID的响应文本，"
                "转换为结构化的QA列表，并复制相关图片到输出目录。"
            )
        else:
            return (
                "LLM output parsing operator."
                "Converts LLM-generated response text containing question and answer IDs"
                "into a structured QA list and copies related images to the output directory."
            )
    
    def _id_to_text(self, input_ids, input_json, image_prefix="images"):
        texts = []
        id_list = input_ids.replace(' ', '').split(',')
        for id in id_list:
            try: 
                int(id)
            except:
                continue
            if int(id) < len(input_json):
                try:
                    item = input_json[int(id)]
                except:
                    continue
                if 'text' in item:
                    texts.append(item['text'])
                elif 'img_path' in item:
                    try:
                        img_path = item.get('img_path', '')
                        img_name = os.path.basename(img_path)
                        new_path = f"{image_prefix}/{img_name}"
                        texts.append(f"![{' '.join(item.get('image_caption','image'))}]({new_path})")
                    except:
                        pass
                elif item.get('type','') == 'list':
                    if item['sub_type'] == 'text':
                        try:
                            texts.append(input_json[int(id)]['list_items'].pop(0))
                        except:
                            pass
        return '\n'.join(texts)
    
    def _convert_response(self, input_response, input_json_path, image_prefix="images"):
        qa_list = []
        with open(input_json_path, 'r') as infile:
            input_json = list(json.load(infile))
        # 提取title
        for chapter_block in re.findall(r'<chapter>(.*?)</chapter>', input_response, flags=re.DOTALL):
            title = re.search(r'<title>(.*?)</title>', chapter_block, flags=re.DOTALL)
            if title:
                chapter_title = self._id_to_text(title.group(1).strip(), input_json, image_prefix)
            else:
                chapter_title = ""
            # 找出所有 qa_pair 块
            for pair in re.findall(r'<qa_pair>(.*?)</qa_pair>', chapter_block, flags=re.DOTALL):
                # 提取 question 部分
                q_match = re.search(r'<question>(.*?)</question>', pair, flags=re.DOTALL)
                # 提取 answer 部分
                a_match = re.search(r'<answer>(.*?)</answer>', pair, flags=re.DOTALL)
                # 提取solution部分
                s_match = re.search(r'<solution>(.*?)</solution>', pair, flags=re.DOTALL)
                # 提取label
                label_match = re.search(r'<label>(.*?)</label>', pair, flags=re.DOTALL)
                if not ((q_match and label_match) or (a_match and label_match) or (s_match and label_match)):
                    continue
                label = label_match.group(1).strip()
                qa_list.append({
                    'question': self._id_to_text(q_match.group(1).strip(), input_json, image_prefix) if q_match else "",
                    'answer': a_match.group(1).strip() if a_match else "",
                    'solution': self._id_to_text(s_match.group(1).strip(), input_json, image_prefix) if s_match else "",
                    'label': label,
                    'chapter_title': chapter_title
                })
        return qa_list
    
    def run(self, storage: DataFlowStorage,
            input_response_path_key,
            input_converted_layout_path_key,
            input_name_key,
            output_qalist_path_key,
            ):
        dataframe = storage.read("dataframe")
        
        # Response 转换
        for idx, row in dataframe.iterrows():
            converted_json_path = row[input_converted_layout_path_key]
            response = Path(row[input_response_path_key]).read_text(encoding='utf-8')
            name = row[input_name_key]
            
            image_prefix = os.path.join(name, f"{self.mode}_images")
            qa_list = self._convert_response(response, converted_json_path, image_prefix)
            output_qalist_path = os.path.join(self.output_dir, name, f"extracted_{self.mode}s.jsonl")
            os.makedirs(os.path.dirname(output_qalist_path), exist_ok=True)
            with open(output_qalist_path, 'w') as outfile:
                for qa in qa_list:
                    json.dump(qa, outfile, ensure_ascii=False)
                    outfile.write('\n')
            
            # 复制图片
            src_dir = os.path.join(self.intermediate_dir, 'mineru', Path(converted_json_path).stem).replace('_content_list_converted','')
            src_images = os.path.join(src_dir, 'vlm', 'images')
            dst_images = os.path.join(self.output_dir, image_prefix)
            
            try:
                if os.path.exists(src_images):
                    shutil.copytree(src_images, dst_images)
                else:
                    self.logger.warning(f"Source images dir does not exist: {src_images}")
            except Exception as e:
                self.logger.warning(f"Failed to copy images from {src_images} to {dst_images}: {e}")
            
            dataframe.loc[idx, output_qalist_path_key] = output_qalist_path
            
        storage.write(dataframe)
        
@OPERATOR_REGISTRY.register()
class QA_Merger(OperatorABC):
    def __init__(self, output_dir, strict_title_match=False):
        self.output_dir = output_dir
        self.strict_title_match = strict_title_match
        
    @staticmethod
    def get_desc(lang: str = "zh") -> str:
        if lang == 'zh':
            return (
                "QA对合并算子。"
                "将问题和答案的QA列表进行合并，生成最终的QA对文件，"
                "并转换为Markdown格式。"
            )
        else:
            return (
                "QA pair merging operator."
                "Merges question and answer QA lists to generate final QA pair files,"
                "and converts them to Markdown format."
            )
    
    def run(self, storage: DataFlowStorage,
            input_question_qalist_path_key,
            input_answer_qalist_path_key,
            input_name_key,
            output_merged_qalist_path_key,
            output_merged_md_path_key,
            output_qa_item_key="qa_item"  # 新增：展开后的 QA 内容列名
            ):
        dataframe = storage.read("dataframe")
        
        # 为了能存储 list 对象，先初始化该列为 object 类型
        dataframe[output_qa_item_key] = None
        dataframe[output_qa_item_key] = dataframe[output_qa_item_key].astype(object)

        for idx, row in dataframe.iterrows():
            question_qalist_path = row[input_question_qalist_path_key]
            answer_qalist_path = row[input_answer_qalist_path_key]
            name = row[input_name_key]
            
            output_merged_qalist_path = os.path.join(self.output_dir, name, "merged_qa_pairs.jsonl")
            merge_qa_pair(question_qalist_path, answer_qalist_path, output_merged_qalist_path, strict_title_match=self.strict_title_match)
            
            output_merged_md_path = os.path.join(self.output_dir, name, "merged_qa_pairs.md")
            jsonl_to_md(output_merged_qalist_path, output_merged_md_path)
            
            qa_pairs = []
            if os.path.exists(output_merged_qalist_path):
                with open(output_merged_qalist_path, 'r', encoding='utf-8') as f:
                    qa_pairs = [json.loads(line) for line in f]
            
            dataframe.at[idx, output_qa_item_key] = qa_pairs

            dataframe.loc[idx, output_merged_qalist_path_key] = output_merged_qalist_path
            dataframe.loc[idx, output_merged_md_path_key] = output_merged_md_path
            
        dataframe = dataframe.explode(output_qa_item_key).reset_index(drop=True)

        storage.write(dataframe)